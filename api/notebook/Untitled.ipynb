{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4e6aa1e2-e383-47c2-ad40-75c801fc801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import pinecone\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "71a1cc99-b83d-4329-9050-ef0acd467a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2d436-d6a3-4148-946f-c272724b4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingGenerator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "class DocumentIndexer:\n",
    "    def __init__(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1160c3bd-98ac-4344-ac2d-50eb22823403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from voyager import Index, Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55520f9b-f7bb-4040-96e6-0988e2b2d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(COHERE_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "0002190f-9116-4a4e-917b-64ddbaa937c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index('document-indexer', dimension=1024, metadata_config={\"indexed\": [\"user_id\", \"document_id\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "c3a44955-584f-4437-8941-3a9c9e1e3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tika\n",
    "tika.initVM()\n",
    "from tika import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "36a67028-b67b-4421-b648-2e8b94b484c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader \n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def format_line(line: str) -> str:\n",
    "    return line.replace('\\n', '')\n",
    "\n",
    "def paragraph_splitter(lines: str, max_char: int = 4000) -> list[str]:\n",
    "    paragraphs = []\n",
    "    paragraph = ''\n",
    "    for line in lines:\n",
    "        paragraph += ' ' + line\n",
    "        if len(paragraph) >= max_char:\n",
    "            paragraphs.append(paragraph)\n",
    "            paragraph = ''\n",
    "    if len(paragraph) > 0:\n",
    "        paragraphs.append(paragraph)\n",
    "    return paragraphs\n",
    "    \n",
    "\n",
    "def get_text_from_pdf(filename: str) -> list[str]:\n",
    "    lines = [format_line(line) for line in sent_tokenize(parser.from_file(filename)['content'])]\n",
    "    return paragraph_splitter(lines)\n",
    "\n",
    "def add_document(filename, user_id, document_id):\n",
    "    texts = get_text_from_pdf(filename)\n",
    "    print(len(texts))\n",
    "    response = co.embed(\n",
    "      texts=texts,\n",
    "      model='embed-multilingual-v3.0',\n",
    "      input_type='search_document'\n",
    "    )\n",
    "    index_map[(user_id, document_id)] = index = Index(Space.Cosine, num_dimensions=1024)\n",
    "    upsert_response = index.upsert(\n",
    "        vectors=[\n",
    "            (\n",
    "             f\"{user_id}_{document_id}_{i}\",\n",
    "             e ,  # Dense vector values\n",
    "            {\"user_id\": user_id, \"document_id\": document_id, \"sentence_id\": i, \"text\": text}\n",
    "            )\n",
    "            for i, (text, e) in enumerate(zip(texts, response.embeddings))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "7c2cfd67-00e0-4c26-a7cd-a747eaee1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, user_id, document_id):\n",
    "    index = pinecone.Index(\"document-indexer\")\n",
    "    embedding = co.embed(\n",
    "          texts=[question],\n",
    "          model='embed-multilingual-v3.0',\n",
    "          input_type='search_query'\n",
    "        ).embeddings[0]\n",
    "    query_response = index.query(\n",
    "        top_k=3,\n",
    "        vector=embedding,\n",
    "        filter={\n",
    "            \"user_id\": {\"$eq\": user_id},\n",
    "            \"document_id\": {\"$eq\": document_id},\n",
    "        },\n",
    "        include_metadata=True\n",
    "    )\n",
    "    answers = [q['metadata']['text'] for q in query_response['matches'] if q['score']]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \n",
    "                 f\"\"\"\n",
    "    The answer to this question \"{question}\" are in the following sentences generate just the answer plus the reasoning of the answer in one line. Answer the question in the language of the question. If there are no answer just output the word \"None\"\n",
    "    {str(answers)}\n",
    "                 \"\"\".strip()}\n",
    "        ],\n",
    "        temperature = 0\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    print(f\"Price: {response.usage.total_tokens * 0.003 / 1000} $\")\n",
    "    reasoning = None\n",
    "    if answer != 'None':\n",
    "        reasoning = answers[0]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "d893b8fd-3986-43cb-84ec-4ea0282237da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "add_document('Resume.pdf', 'hoang', 'resume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "674e4a4c-c369-4baf-a7e2-0328a5b030ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "add_document('transformer.pdf', 'hoang', 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f6437a15-d4dd-4d82-8509-44464959e147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "add_document('mlviet.pdf', 'hoang', 'vietnam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "808cfab1-8884-4032-88b8-5d77eba5d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "add_document('giaithuat.pdf', 'hoang', 'vietgiaithuat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "bed56e60-0d6f-4101-971b-6fed66ff544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: 0.008715 $\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Transformer is good for translation because it replaces recurrent layers with multi-headed self-attention, allowing for faster training and achieving state-of-the-art results.'"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer('Why Transformer is good for translation', 'hoang', 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "3eea656e-9a79-4e19-9b7e-63ee528c25f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_text_from_pdf('transformer.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43026d-3260-4bda-aeeb-ddebf2e1c9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
